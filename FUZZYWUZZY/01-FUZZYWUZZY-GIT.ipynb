{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUZZY MATCHING\n",
    "The problem this file is trying to solve is matching up names that have been manually keyed into a spreadsheet to name that are the \"offical\" version in company HR records.  These are referred to as the \"Alpha\" names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbconn = sqlite3.connect(':memory:')\n",
    "dbconn = sqlite3.connect('pars.db')\n",
    "print(dbconn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = dbconn.cursor()\n",
    "cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the IN files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = r\"C:\\Users\\CHUGHES\\Documents\\PROJECTS\\Python\\001-PARS\\DATA\\HR-ECI-ALLEMP.csv\"\n",
    "p_file = r\"C:\\Users\\CHUGHES\\Documents\\PROJECTS\\Python\\001-PARS\\DATA\\2021-PAR-EDIT.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with PARS file\n",
    "The PARS file has just the LAST, MIDDLE, and FIRST names.  Not the ALPHA which is a Whole Name (Last, First, MI + suffixes)\n",
    "Here, I am just interested in the names and then joining them into a LAST, First format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_header = {1:\"NUMBER\",6:\"LNAME\",8:\"FNAME\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(p_file, index_col=None, header=None, skiprows=1, usecols = [1,6,8])\n",
    "df1.rename(columns = p_header, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure the data is in UPPER Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['LNAME'] = df1['LNAME'].str.upper()\n",
    "df1['FNAME'] = df1['FNAME'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1.index) # Just testing that the number of rows stays the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is code that would split a Whole name field.  It is not needed for this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['P_LNAME'] = df1.NAME_PACS.str.split(',', expand = True)[0] # Not Needed for this exercise\n",
    "# df1['P_FNAME'] = df1.NAME_PACS.str.split(' ', expand = True)[2] # Not Needed for this exercise - splits first and last names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1.index)  # Just testing that the number of rows stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to change data type to a string for the Lamda function to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.astype({\"LNAME\": str}, errors='raise') \n",
    "df1 = df1.astype({\"FNAME\": str}, errors='raise') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the LAST_NAME and FIRST_NAME columns with a \",\" and a SPACE\n",
    "### and adding the new column to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['NAME'] = df1[['LNAME','FNAME']].apply(lambda x: ', '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### will fuzzymatch the \"NAME\" column with the Aplha Roster \"A_NAME\"\n",
    "### column in the other file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1.index)  # Just testing that the number of rows stays the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working the APLHA file (HR DATA)\n",
    "Only interested here in getting the ECI# number and the \"official\" spelling of the person's name.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(a_file)\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_header = {0:\"LOA\",1:\"A_NAME\",3:\"ECI\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(a_file, index_col=None, header=None, skiprows=1, usecols = [0,1,3])\n",
    "df2.rename(columns = a_header, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfunique = len(df2) - df2.nunique()\n",
    "print (dfunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.drop_duplicates(subset=['NAME_ALPHA'],inplace=True)\n",
    "# df2.drop_duplicates(subset=['NAME_PACS'])\n",
    "#df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.astype({\"A_NAME\": str}, errors='raise') \n",
    "# df1 = df1.astype({\"FNAME\": str}, errors='raise') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2['A_NAME'] = df2[['A_LNAME','A_FNAME']].apply(lambda x: ', '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is where the Fuzzy Matching begins.\n",
    "Below are 2 lines of test code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.extractOne(\"HUGHES, A\", df2['A_NAME'].to_list(), score_cutoff=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.extractOne(\"HUGHES, C\", df1['NAME'].to_list(), score_cutoff=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the actual Fuzzy Match\n",
    "(This can take a few minutes to finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['name_from_df2'] = df1['P_NAME'].apply(lambda x: process.extractOne(x, df2['A_NAME'].to_list(),score_cutoff=90))\n",
    "# df2['PAR_NAME'] = df2['A_NAME'].apply(lambda x: process.extractOne(x, df1['NAME'].to_list(),score_cutoff=90))\n",
    "df1['ALPHA_NAME'] = df1['NAME'].apply(lambda x: process.extractOne(x, df2['A_NAME'].to_list(),score_cutoff=90))\n",
    "# df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below takes the ALPHA_NAME list and converts it to an actual column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_name_list = df1['ALPHA_NAME'].to_list()\n",
    "temp_name_list = [_[0] if _ != None else None for _ in temp_name_list]\n",
    "df1['ALPHA_NAME'] = temp_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.drop(columns=['PACR_NAME']) # Ooops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Put the dataframe into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_sql('fuzz',con = dbconn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### I used this query in SQLite to match things up\n",
    "### where 'LOAAlpha is a table with all COMPANY employees\n",
    "### with the LOA and ECI #'s\n",
    "\n",
    "```\n",
    "SELECT f.NUMBER,\n",
    "       l.LOA,\n",
    "       l.ECI,\n",
    "       f.ALPHA_NAME\n",
    "  FROM fuzz f\n",
    "       LEFT JOIN\n",
    "       LOAAlpha L ON f.ALPHA_NAME = l.NAME;\n",
    "\n",
    "```\n",
    "and that's it"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ee07828cb95c6b5b1c8f5e8792024b55c7b92ed3d39e640de503f3abd63df5f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
