{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUZZY MATCHING\n",
    "As with the previous file (01-FUZZYWUZZY-GIT.ipynb) I am matching up more misspelled names to the \"Offical\" name spelling in HR records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbconn = sqlite3.connect(':memory:')\n",
    "dbconn = sqlite3.connect('pars.db')\n",
    "print(dbconn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = dbconn.cursor()\n",
    "cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the IN files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = r\"C:\\Users\\CHUGHES\\Documents\\PROJECTS\\Python\\001-PARS\\DATA\\HR-ECI-ALLEMP.csv\"\n",
    "# p_file = r\"C:\\Users\\CHUGHES\\Documents\\PROJECTS\\Python\\001-PARS\\DATA\\2021-PAR-EDIT.csv\"\n",
    "file1 = r\"C:\\Users\\CHUGHES\\Documents\\PAR Consolidation\\2020\\REWORK-DS\\CSV exports\\2019-Preliminary Assessment Review Database - February 2020-NO_PRA.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with PARS file\n",
    "Naming the column headers I am interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_header = {0:\"NUMBER\",1:\"OPEN_DATE\",2:\"SOURCE\", 3:\"LNAME\",4:\"MNAME\",5:\"FNAME\",6:\"OFFICE\",7:\"CLOSED_DATE\",8:\"DET_COM\",9:\"INQUIRY\",10:\"WORKED_BY\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting only the columns I want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv(file1, index_col=None)\n",
    "df1 = pd.read_csv(file1, index_col=None, header=None, skiprows=1, usecols = [0,1,2,3,4,5,6,7,8,9,10])\n",
    "df1.rename(columns = p_header, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure the data is in UPPER Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = map(str.upper, df1.columns) #  Make all the column headers upper case\n",
    "df1['LNAME'] = df1['LNAME'].str.upper()\n",
    "df1['FNAME'] = df1['FNAME'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1.index) # Just testing that the number of rows stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['P_LNAME'] = df1.NAME_PACS.str.split(',', expand = True)[0] # Not Needed for this exercise\n",
    "# df1['P_FNAME'] = df1.NAME_PACS.str.split(' ', expand = True)[2] # Not Needed for this exercise - splits first and last names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1.index)  # Just testing that the number of rows stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to change data type to a string for the Lamda function to work\n",
    "###  Also converting the string value of the Date fields to DateTime and \n",
    "### then to just a DATE\n",
    "I just like the short dates, without all the zeros.  And I want YYYY-MM-DD format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.astype({\"LNAME\": str}, errors='raise') \n",
    "df1 = df1.astype({\"FNAME\": str}, errors='raise')\n",
    "# df1['OPEN_DATE'].dt.date\n",
    "df1['OPEN_DATE'] = pd.to_datetime(df1['OPEN_DATE']).dt.strftime('%Y-%m-%d')\n",
    "df1['CLOSED_DATE'] = pd.to_datetime(df1['CLOSED_DATE']).dt.strftime('%Y-%m-%d')\n",
    "df1['OPEN_DATE'] = pd.to_datetime(df1['OPEN_DATE'])\n",
    "df1['CLOSED_DATE'] = pd.to_datetime(df1['CLOSED_DATE'])\n",
    "# df1['OPEN_DATE'].dt.date\n",
    "# df1['CLOSED_DATE'].dt.date\n",
    "df1['OPEN_DATE'] = pd.to_datetime(df1['OPEN_DATE']).dt.date\n",
    "df1['CLOSED_DATE'] = pd.to_datetime(df1['CLOSED_DATE']).dt.date\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this worked correctly, when inserted into SQLITE it will have the dates formated the way I want them.  AND the structure will indicate \"DATE\"  not DATETIME(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the LAST_NAME and FIRST_NAME columns with a \",\" and a SPACE\n",
    "### and adding the new column to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['NAME'] = df1[['LNAME','FNAME']].apply(lambda x: ', '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### will fuzzymatch the \"NAME\" column with the Aplha Roster \"A_NAME\"\n",
    "### column in the other file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1.index)  # Just testing that the number of rows stays the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working the APLHA file (HR DATA)\n",
    "I think the function below is identical to the first file (01-FUZZYWUZZY-GIT.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(a_file)\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_header = {0:\"LOA\",1:\"A_NAME\",3:\"ECI\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(a_file, index_col=None, header=None, skiprows=1, usecols = [0,1,3])\n",
    "df2.rename(columns = a_header, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfunique = len(df2) - df2.nunique()\n",
    "print (dfunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.drop_duplicates(subset=['NAME_ALPHA'],inplace=True)\n",
    "# df2.drop_duplicates(subset=['NAME_PACS'])\n",
    "#df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.astype({\"A_NAME\": str}, errors='raise') \n",
    "# df1 = df1.astype({\"FNAME\": str}, errors='raise') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2['A_NAME'] = df2[['A_LNAME','A_FNAME']].apply(lambda x: ', '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.extractOne(\"HUGHES, A\", df2['A_NAME'].to_list(), score_cutoff=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.extractOne(\"HUGHES, C\", df1['NAME'].to_list(), score_cutoff=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the actual Fuzzy Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['name_from_df2'] = df1['P_NAME'].apply(lambda x: process.extractOne(x, df2['A_NAME'].to_list(),score_cutoff=90))\n",
    "# df2['PAR_NAME'] = df2['A_NAME'].apply(lambda x: process.extractOne(x, df1['NAME'].to_list(),score_cutoff=90))\n",
    "df1['ALPHA_NAME'] = df1['NAME'].apply(lambda x: process.extractOne(x, df2['A_NAME'].to_list(),score_cutoff=90))\n",
    "# df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_name_list = df1['ALPHA_NAME'].to_list()\n",
    "temp_name_list = [_[0] if _ != None else None for _ in temp_name_list]\n",
    "df1['ALPHA_NAME'] = temp_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.drop(columns=['PACR_NAME']) # Ooops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Put the dataframe into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_sql('fuzz_19',con = dbconn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### I used this query in SQLite to match things up\n",
    "### where 'LOAAlpha is a table with all COMPANY employees\n",
    "### with the LOA and ECI #'s\n",
    "\n",
    "```\n",
    "SELECT f.NUMBER,\n",
    "       f.OPEN_DATE,\n",
    "       f.SOURCE,\n",
    "       l.LOA,\n",
    "       l.ECI,\n",
    "       f.LNAME,\n",
    "       f.MNAME,\n",
    "       f.FNAME,\n",
    "       f.OFFICE,\n",
    "       f.CLOSED_DATE,\n",
    "       f.DET_COM,\n",
    "       f.INQUIRY,\n",
    "       f.WORKED_BY,\n",
    "       f.NAME,\n",
    "       f.ALPHA_NAME\n",
    "  FROM fuzz_19 f\n",
    "       LEFT JOIN\n",
    "       LOAAlpha L ON f.ALPHA_NAME = l.NAME;\n",
    "\n",
    "```\n",
    "and that's it"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ee07828cb95c6b5b1c8f5e8792024b55c7b92ed3d39e640de503f3abd63df5f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
